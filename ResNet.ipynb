{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet-18 Architecture:**\n",
        "\n",
        "Initial Convolution Layer:\n",
        "\n",
        "1 Conv2D (3×3)\n",
        "\n",
        "1 BatchNorm\n",
        "\n",
        "1 ReLU activation\n",
        "\n",
        "(This is not counted in the \"18\" because BatchNorm and activation don't have trainable parameters)\n",
        "\n",
        "\n",
        "**Residual Layers**\n",
        "\n",
        "Layer 1: 2 × BasicBlock\n",
        "\n",
        "(each has 2 Conv layers) → 4 conv layers\n",
        "\n",
        "Layer 2: 2 × BasicBlock → 4 conv layers\n",
        "\n",
        "Layer 3: 2 × BasicBlock → 4 conv layers\n",
        "\n",
        "Layer 4: 2 × BasicBlock → 4 conv layers\n",
        "\n",
        "Final Fully Connected Layer:\n",
        "\n",
        "1 Linear (FC) layer\n",
        "\n",
        "\n",
        "Thus, the total number of trainable layers =\n",
        "\n",
        "1\n",
        "+\n",
        "4\n",
        "+\n",
        "4\n",
        "+\n",
        "4\n",
        "+\n",
        "4\n",
        "+\n",
        "1\n",
        "=\n",
        "18\n",
        "1+4+4+4+4+1=18\n",
        "\n"
      ],
      "metadata": {
        "id": "2L7_P1KUFnFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "avvVsfduZPoN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g7Kjlio3Ptz5"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1):\n",
        "      super(BasicBlock, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 3, padding = 1 , stride = 1)\n",
        "      self.bn1 = nn.BatchNorm2d(num_features = out_channels)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.conv2 = nn.conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = 3, padding = 1, stride = 1)\n",
        "      self.bn2 = nn.BatchNorm2d(num_features = out_channels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "forward method for the basic block"
      ],
      "metadata": {
        "id": "sRZaAWnnMpx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "  identity = x\n",
        "  x = self.conv1(x)\n",
        "  x = self.bn1(x)\n",
        "  x = self.relu(x)\n",
        "\n",
        "  x = self.conv2(x)\n",
        "  x = self.bn2(x)\n",
        "  x = x + identity #f(x) + x shortcut\n",
        "\n",
        "  return(self.relu(x))"
      ],
      "metadata": {
        "id": "jrpHDWReahuh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "  layers= []\n",
        "  for stride in stride:\n",
        "    layers.append(block(self.in_channels, out_channels, stride))\n",
        "    self.in_channels = out_channels\n",
        "  return nn.Sequential(layers)"
      ],
      "metadata": {
        "id": "Vac4_3eAJnmr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNEt18(nn.Module):\n",
        "  def __init__(self, num_classes = 10):\n",
        "    super(ResNet18, self).__init__()\n",
        "    self.in_channels = 64\n",
        "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.Relu()\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "    self.layer1 = self._make_layer(BasicBlock, 64, 2, stride = 1)\n",
        "    self.layer2 = self._make_layer(BasicBlock, 128, 2, stride = 1)\n",
        "    self.layer3 = self._make_layer(BasicBlock, 256, 2, stride = 1)\n",
        "    self.layer4 = self._make_layer(BasicBlock, 512, 2, stride =1)\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_7MY2gZ9HQDy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "  x = self.conv1(x)\n",
        "  x = self.bn1(x)\n",
        "  x = self.relu(x)\n",
        "  x = self.maxpool(x)\n",
        "\n",
        "  x = self.layer1(x)\n",
        "  x = self.layer2(x)\n",
        "  x = self.layer3(x)\n",
        "  x = self.layer4(x)\n",
        "\n",
        "  x = self.avgpool(x)\n",
        "  x = self.fc(x)\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "tKhhE6F-bRBw"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}